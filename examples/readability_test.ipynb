{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability Test for Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q py-readability-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readability import Readability\n",
    "import re\n",
    "def checkFleschScore(text):\n",
    "    text = re.sub(r\" +\",\" \",text)\n",
    "    r = Readability(text)\n",
    "    if r.statistics()[\"num_words\"] < 100:\n",
    "        r = Readability(\" \".join([text] * (100 // r.statistics()[\"num_words\"] + 1)))\n",
    "    return r.flesch().grade_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_explanations = [\n",
    "    \"Load the dataset that will be used for the regression analysis. This is the first step in the workflow and is essential for initializing the dataset for subsequent steps.\",\n",
    "    \"Select the dependent variable (also known as the target variable) from the dataset. This variable is what the model will try to predict based on the independent variables.\",\n",
    "    \"Check for outliers in the independent variables. One of the least squares assumptions is that large outliers are unlikely. Outliers can significantly affect the regression model. Even if it seems like extreme observations have been recorded correctly, it is advisable to exclude them or perform data transformation on them before estimating.\",\n",
    "    \"Select the independent variables (also known as the predictors or features) that will be used to predict the dependent variable. This step involves choosing the relevant variables based on certain criteria.\",\n",
    "    \"Check for outliers in the independent variables. One of the least squares assumptions is that large outliers are unlikely. Outliers can significantly affect the regression model. Even if it seems like extreme observations have been recorded correctly, it is advisable to exclude them or perform data transformation on them before estimating.\",\n",
    "    \"Check for multicollinearity among independent variables. Multicollinearity occurs when two or more independent variables are highly correlated. It can inflate the variance of the coefficient estimates, leading to less precise estimations. The Variance Inflation Factor (VIF) measures how much the variance of the estimated regression coefficient increases if your predictors are correlated. It is a common way to detect multicollinearity.\\\n",
    "    The VIF of X exceeds 10. It is a sign of serious multicollinearity. It may inflate the variance of its coefficient estimate. You may want to consider changing the predictors in your model.\",\n",
    "    \"Check for multicollinearity among independent variables. Multicollinearity occurs when two or more independent variables are highly correlated. It can inflate the variance of the coefficient estimates, leading to less precise estimations. The Variance Inflation Factor (VIF) measures how much the variance of the estimated regression coefficient increases if your predictors are correlated. It is a common way to detect multicollinearity.\\\n",
    "    A VIF of X above 4 raises concerns, but it is not a big issue.\",\n",
    "    \"Check for multicollinearity among independent variables. Multicollinearity occurs when two or more independent variables are highly correlated. It can inflate the variance of the coefficient estimates, leading to less precise estimations. The Variance Inflation Factor (VIF) measures how much the variance of the estimated regression coefficient increases if your predictors are correlated. It is a common way to detect multicollinearity.\\\n",
    "    A VIF of X lower than 4 is not a big issue.\",\n",
    "    \"Split the dataset into training and testing sets. The training set is used to train the regression model, while the testing set is used to evaluate its generalizability performance.\",\n",
    "    \"Use independent and dependent variables to train the model and predict the outcome.\",\n",
    "    '''Evaluate the performance of the trained regression model. This step involves calculating evaluation metrics like Mean Squared Error (MSE) and R-squared (R2) to assess the model's accuracy and goodness of fit. Here are the available commands for exporting various elements of your analysis.\\\n",
    "        Regression Table (LaTeX format): obj.export(\"table\", format=\"latex\").\n",
    "    Analysis Report on the coefficients: exported_report = obj.export(\"report\").\n",
    "    Model Export: exported_model = obj.export(\"model\").\n",
    "    Dataset Export, if transformations were applied: exported_dataset = obj.export(\"dataset\").\n",
    "    Note: Replace obj with the name of the instance you've created for your analysis.'''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10', '11', '12'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['college']]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(checkFleschScore,lr_explanations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_explanations = [\n",
    "    \"Initiate the analysis by loading the dataset to be used in the t-test. This initial step is crucial for setting up the data for the steps that follow.\",\n",
    "    \"Identify the independent variable for the t-test. This variable is the focus of the analysis and the basis for comparison between groups.\",\n",
    "    \"Examine the data for outliers that could potentially skew the results. Outliers are extreme values that deviate from other observations in the dataset.\",\n",
    "    \"Select the group variable which categorizes data into groups for comparison. This step is about defining the groups that will be compared in the t-test.\",\n",
    "    \"Assess the homogeneity of variances between the two groups using Levene's test. Equal variances across samples is called homogeneity of variance. Levene's test is used to test if samples have equal variances.\",\n",
    "    \"Two independent samples t-Test requires the two groups have normal distributions. In practice, the method is robust to violations of the normal population assumption. This is especially true when both n1 and n2 are at least about 30, by the Central Limit Theorem. The Shapiro-Wilk test tests whether a random sample comes from a normal distribution.\",\n",
    "    \"Formulate the null and alternative hypotheses for the t-test and define the Type I Error (alpha). This step is crucial as it frames the statistical test and sets the significance level at which the null hypothesis will be tested against the alternative.\",\n",
    "    \"Conduct the t-test to evaluate the statistical significance of the difference between the two groups. This step will compare the observed test statistic to the critical value determined by the Alpha Level rate, leading to a decision on the null hypothesis.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8', '9'],\n",
       " ['college'],\n",
       " ['college'],\n",
       " ['10', '11', '12'],\n",
       " ['college'],\n",
       " ['10', '11', '12'],\n",
       " ['college'],\n",
       " ['college']]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(checkFleschScore,ttest_explanations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
